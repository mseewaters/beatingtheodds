{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature creation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Week', 'Day', 'Date', 'Time', 'Winner', 'LoserIsHome',\n",
      "       'Loser', 'PtsW', 'PtsL', 'YdsW', 'TOW', 'YdsL', 'TOL', 'season', 'week',\n",
      "       'Winner Abbr', 'Loser Abbr', 'Home Team', 'Away Team', 'Home Score',\n",
      "       'Away Score', 'Winner Yds', 'Loser Yds', 'Margin Yds', 'Winner TO',\n",
      "       'Loser TO', 'Margin TO', 'Margin Pts', 'Total Pts', 'Margin Pct',\n",
      "       'home_team_winner', 'away_win_bonus', 'DateTime',\n",
      "       'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "df_results = pd.read_csv('../data/nfl_games_pfr.csv')\n",
    "print(df_results.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rankings using pagerank from nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Graph Functions\n",
    "def create_graph(game_data, week_num):\n",
    "    G = nx.DiGraph()\n",
    "    margin_totals = defaultdict(float)\n",
    "    game_counts = defaultdict(int)\n",
    "    \n",
    "    # Iterate over each game result\n",
    "    for _, row in game_data.iterrows():\n",
    "        winner = row['winner']\n",
    "        loser = row['loser']\n",
    "        week = row['week']\n",
    "        margin = row['margin']\n",
    "\n",
    "        key = (loser, winner)\n",
    "        margin_totals[key] += margin\n",
    "        game_counts[key] += 1\n",
    "\n",
    "    # Add edges with average margin as weight\n",
    "    for (loser, winner), total_margin in margin_totals.items():\n",
    "        avg_margin = total_margin / game_counts[(loser, winner)]\n",
    "        G.add_edge(loser, winner, weight=avg_margin)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Function to calculate rankings based on the weighted graph\n",
    "def calculate_rankings(graph):\n",
    "    # Calculate PageRank with weights\n",
    "    return pd.DataFrame(nx.pagerank(graph, alpha=0.95, weight='weight').items(), columns=['Team', 'Ranking'])\n",
    "\n",
    "# Function to generate rankings for each season and week\n",
    "def generate_rankings(df_filtered, feature_type):\n",
    "    # Initialize an empty list to store rankings DataFrames\n",
    "    ranking_dfs = []\n",
    "\n",
    "    # Loop over each distinct season in the dataset\n",
    "    for season in df_filtered['season'].unique():\n",
    "        # Filter the game data for the current season\n",
    "        season_data = df_filtered[df_filtered['season'] == season]\n",
    "        \n",
    "        # Loop over the weeks for this season\n",
    "        for week in range(2, season_data['week'].max() + 1):\n",
    "            # Filter the game data up to the current week for the current season\n",
    "            filtered_data = season_data[season_data['week'] <= week]\n",
    "            \n",
    "            # Create the directed graph for the current season and weeks\n",
    "            G = create_graph(filtered_data, week)\n",
    "            \n",
    "            # Calculate the rankings based on the weighted graph\n",
    "            rankings = calculate_rankings(G)\n",
    "\n",
    "            # Round the rankings to 4 decimal places\n",
    "            rankings['Ranking'] = rankings['Ranking'].round(5)\n",
    "            \n",
    "            # Add columns indicating the season and week, with a leading zero for weeks\n",
    "            rankings['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "            rankings['Season'] = season\n",
    "            rankings['Week'] = week\n",
    "            rankings['Type'] = feature_type\n",
    "            \n",
    "            # Append the rankings to the list\n",
    "            ranking_dfs.append(rankings)\n",
    "    \n",
    "    # Concatenate all rankings DataFrames into a single DataFrame\n",
    "    return pd.concat(ranking_dfs)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Strength of Schedule (SoS)\n",
    "def calculate_strength_of_schedule(graph, pagerank):\n",
    "    sos = defaultdict(float)\n",
    "    for team in graph.nodes:\n",
    "        opponents = list(graph.predecessors(team)) + list(graph.successors(team))\n",
    "        if opponents:\n",
    "            sos[team] = sum(pagerank.get(opponent, 0) for opponent in opponents) / len(opponents)\n",
    "        else:\n",
    "            sos[team] = 0\n",
    "    return sos\n",
    "\n",
    "# Function to generate rankings for each season and week with SoS and iteration\n",
    "def generate_rankings_with_sos(df_filtered, feature_type, iterations=20):\n",
    "    # Initialize an empty list to store rankings DataFrames\n",
    "    ranking_dfs = []\n",
    "\n",
    "    # Loop over each distinct season in the dataset\n",
    "    for season in df_filtered['season'].unique():\n",
    "        # Filter the game data for the current season\n",
    "        season_data = df_filtered[df_filtered['season'] == season]\n",
    "\n",
    "        # Loop over the weeks for this season\n",
    "        for week in range(2, season_data['week'].max() + 1):\n",
    "            # Filter the game data up to the current week for the current season\n",
    "            filtered_data = season_data[season_data['week'] <= week]\n",
    "            \n",
    "            # Create the directed graph for the current season and weeks\n",
    "            G = create_graph(filtered_data, week)\n",
    "            \n",
    "            # Initial PageRank calculation\n",
    "            pagerank = dict(nx.pagerank(G, alpha=0.9, weight='weight'))\n",
    "\n",
    "            # Iteratively refine the rankings with SoS\n",
    "            for _ in range(iterations):\n",
    "                sos = calculate_strength_of_schedule(G, pagerank)\n",
    "                \n",
    "                # Adjust rankings based on strength of schedule\n",
    "                adjusted_pagerank = {}\n",
    "                for team, rank in pagerank.items():\n",
    "                    adjusted_pagerank[team] = rank * (1 + sos[team])  # Adjust by SoS\n",
    "                \n",
    "                # Normalize adjusted PageRank\n",
    "                total_rank = sum(adjusted_pagerank.values())\n",
    "                pagerank = {team: rank / total_rank for team, rank in adjusted_pagerank.items()}\n",
    "\n",
    "            # Convert pagerank dict to DataFrame\n",
    "            rankings = pd.DataFrame(pagerank.items(), columns=['Team', 'Ranking'])\n",
    "\n",
    "            # Round the rankings to 5 decimal places\n",
    "            rankings['Ranking'] = rankings['Ranking'].round(5)\n",
    "            \n",
    "            # Add columns indicating the season and week, with a leading zero for weeks\n",
    "            rankings['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "            rankings['Season'] = season\n",
    "            rankings['Week'] = week\n",
    "            rankings['Type'] = feature_type\n",
    "            \n",
    "            # Append the rankings to the list\n",
    "            ranking_dfs.append(rankings)\n",
    "    \n",
    "    # Concatenate all rankings DataFrames into a single DataFrame\n",
    "    return pd.concat(ranking_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.00824   2024_W02    2024     2  Offense\n",
      "1  BAL  0.01699   2024_W02    2024     2  Offense\n",
      "2  PHI  0.00787   2024_W02    2024     2  Offense\n",
      "3   GB  0.00971   2024_W02    2024     2  Offense\n",
      "4  ATL  0.01507   2024_W02    2024     2  Offense\n",
      "5056\n"
     ]
    }
   ],
   "source": [
    "### OFFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_offense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Yds','Loser Yds','Margin Yds']]\n",
    "df_offense = df_offense.rename(columns={'Winner Yds':'winner', 'Loser Yds':'loser','Margin Yds':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_offense_rankings_df = generate_rankings(df_offense, \"Offense\")\n",
    "final_offense_rankings_df = generate_rankings_with_sos(df_offense, \"Offense\")\n",
    "print(final_offense_rankings_df.head())\n",
    "print(len(final_offense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0  BAL  0.02944   2024_W02    2024     2  Defense\n",
      "1   KC  0.04842   2024_W02    2024     2  Defense\n",
      "2   GB  0.02208   2024_W02    2024     2  Defense\n",
      "3  PHI  0.04614   2024_W02    2024     2  Defense\n",
      "4  PIT  0.01657   2024_W02    2024     2  Defense\n",
      "5056\n"
     ]
    }
   ],
   "source": [
    "### DEFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_defense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner TO','Loser TO','Margin TO']]\n",
    "df_defense = df_defense.rename(columns={'Winner TO':'winner', 'Loser TO':'loser','Margin TO':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_defense_rankings_df = generate_rankings(df_defense, \"Defense\")\n",
    "final_defense_rankings_df = generate_rankings_with_sos(df_defense, \"Defense\")\n",
    "print(final_defense_rankings_df.head())\n",
    "print(len(final_defense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week   Type\n",
      "0  BAL  0.01243   2024_W02    2024     2  Score\n",
      "1   KC  0.01916   2024_W02    2024     2  Score\n",
      "2   GB  0.02459   2024_W02    2024     2  Score\n",
      "3  PHI  0.05097   2024_W02    2024     2  Score\n",
      "4  ATL  0.09120   2024_W02    2024     2  Score\n",
      "5056\n"
     ]
    }
   ],
   "source": [
    "### SCORE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_score = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Abbr','Loser Abbr','Margin Pts']]\n",
    "df_score = df_score.rename(columns={'Winner Abbr':'winner', 'Loser Abbr':'loser', 'Margin Pts':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_score_rankings_df = generate_rankings(df_score, \"Score\")\n",
    "final_score_rankings_df = generate_rankings_with_sos(df_score, \"Score\")\n",
    "print(final_score_rankings_df.head())\n",
    "print(len(final_score_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.00824   2024_W02    2024     2  Offense\n",
      "1  BAL  0.01699   2024_W02    2024     2  Offense\n",
      "2  PHI  0.00787   2024_W02    2024     2  Offense\n",
      "3   GB  0.00971   2024_W02    2024     2  Offense\n",
      "4  ATL  0.01507   2024_W02    2024     2  Offense\n",
      "15168\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all feature rankings into a single DataFrame\n",
    "final_rankings_df = pd.concat([final_offense_rankings_df, final_score_rankings_df, final_defense_rankings_df])\n",
    "print(final_rankings_df.head())\n",
    "print(len(final_rankings_df))\n",
    "final_rankings_df.to_csv('../data/nfl_rankings_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_for_game(game_row, full_data):\n",
    "    current_season = game_row['season']\n",
    "    current_week = game_row['week']\n",
    "    \n",
    "    # Get relevant seasons: current season and previous 3\n",
    "    relevant_seasons = [current_season - i for i in range(4)]\n",
    "    \n",
    "    # Filter data to only include these seasons\n",
    "    filtered_data = full_data[(full_data['season'].isin(relevant_seasons)) & \n",
    "                              ((full_data['season'] < current_season) | \n",
    "                               ((full_data['season'] == current_season) & \n",
    "                                (full_data['week'] < current_week)))]\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team  Home_Avg_Diff  Away_Avg_Diff  Home_Impact  Away_Impact  \\\n",
      "0     ARI         -6.806          2.417       -9.222        9.222   \n",
      "1     ATL          1.389          6.889       -5.500        5.500   \n",
      "2     BAL         -1.556          1.306       -2.861        2.861   \n",
      "3     BUF         12.333         -9.639       21.972      -21.972   \n",
      "4     CAR          1.222         10.222       -9.000        9.000   \n",
      "...   ...            ...            ...          ...          ...   \n",
      "4474  SEA          6.667         -6.667       13.333      -13.333   \n",
      "4475   SF         -1.000         16.333      -17.333       17.333   \n",
      "4476   TB         -4.333          2.500       -6.833        6.833   \n",
      "4477  TEN         -2.333         10.167      -12.500       12.500   \n",
      "4478  WAS          0.000         -2.667        2.667       -2.667   \n",
      "\n",
      "      Matchup_Count SeasonWeek  Season  Week  \n",
      "0                20   2024_W05    2024     5  \n",
      "1                20   2024_W05    2024     5  \n",
      "2                19   2024_W05    2024     5  \n",
      "3                19   2024_W05    2024     5  \n",
      "4                19   2024_W05    2024     5  \n",
      "...             ...        ...     ...   ...  \n",
      "4474             12   2016_W17    2016    17  \n",
      "4475             12   2016_W17    2016    17  \n",
      "4476             12   2016_W17    2016    17  \n",
      "4477             12   2016_W17    2016    17  \n",
      "4478             12   2016_W17    2016    17  \n",
      "\n",
      "[4479 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df_fieldadv = df_results[~df_results['Margin Yds'].isna()][['season','week','Home Team','Away Team','Home Score', 'Away Score']]\n",
    "df_fieldadv['Margin HomeAway'] = df_fieldadv['Home Score'] - df_fieldadv['Away Score']\n",
    "\n",
    "# List to store the aggregated team-level impacts across all weeks\n",
    "all_team_impacts = []\n",
    "\n",
    "# Dictionary to store performance data for home and away impacts\n",
    "home_away_impacts = []\n",
    "\n",
    "# Iterate over each season and week in the dataset\n",
    "for season in df_fieldadv['season'].unique():\n",
    "    for week in df_fieldadv[df_fieldadv['season'] == season]['week'].unique():\n",
    "        # Filter games up to the current season and week, including the current season and the three prior seasons\n",
    "        relevant_games = df_fieldadv[(df_fieldadv['season'] >= (season - 3)) & ((df_fieldadv['season'] < season) | ((df_fieldadv['season'] == season) & (df_fieldadv['week'] <= week)))]\n",
    "        \n",
    "        # Get a list of unique teams for the relevant period\n",
    "        teams = relevant_games['Home Team'].unique()\n",
    "        \n",
    "        for team in teams:\n",
    "            # Filter games where the team is either home or away\n",
    "            home_games = relevant_games[relevant_games['Home Team'] == team]\n",
    "            away_games = relevant_games[relevant_games['Away Team'] == team]\n",
    "\n",
    "            # Iterate over each opponent the team has faced\n",
    "            for opponent in home_games['Away Team'].unique():\n",
    "                # Check if the team played both a home and away game against this opponent\n",
    "                if opponent in away_games['Home Team'].values:\n",
    "                    # Home game(s) against this opponent\n",
    "                    home_matchups = home_games[home_games['Away Team'] == opponent]\n",
    "                    # Away game(s) against this opponent\n",
    "                    away_matchups = away_games[away_games['Home Team'] == opponent]\n",
    "\n",
    "                    # Ensure there is at least one home and one away game\n",
    "                    if not home_matchups.empty and not away_matchups.empty:\n",
    "                        # Compute the average points differential at home and away\n",
    "                        home_avg_diff = home_matchups['Margin HomeAway'].mean()\n",
    "                        away_avg_diff = away_matchups['Margin HomeAway'].mean()\n",
    "\n",
    "                        # Count the number of matchups used in the calculations\n",
    "                        num_matchups = len(home_matchups) + len(away_matchups)\n",
    "\n",
    "                        # Store the impact data for home and away\n",
    "                        home_away_impacts.append({\n",
    "                            'Team': team,\n",
    "                            'Opponent': opponent,\n",
    "                            'Home_Avg_Diff': home_avg_diff,\n",
    "                            'Away_Avg_Diff': away_avg_diff,\n",
    "                            'Home_Impact': home_avg_diff - away_avg_diff,\n",
    "                            'Away_Impact': away_avg_diff - home_avg_diff,\n",
    "                            'Matchup_Count': num_matchups,\n",
    "                            'SeasonWeek': f\"{season}_W{str(week).zfill(2)}\"\n",
    "                        })\n",
    "\n",
    "        # Convert the results to a DataFrame for the current season and week\n",
    "        home_away_impact_df = pd.DataFrame(home_away_impacts)\n",
    "        \n",
    "        # Filter matchups with more than 3 games for the current season and week\n",
    "        filtered_impact_df = home_away_impact_df[(home_away_impact_df['SeasonWeek'] == f\"{season}_W{str(week).zfill(2)}\") & (home_away_impact_df['Matchup_Count'] > 3)]\n",
    "        \n",
    "        # Group by team and calculate the mean home vs away impact\n",
    "        team_home_away_impact = filtered_impact_df.groupby('Team').agg({\n",
    "            'Home_Avg_Diff': 'mean',\n",
    "            'Away_Avg_Diff': 'mean',\n",
    "            'Home_Impact': 'mean',\n",
    "            'Away_Impact': 'mean',\n",
    "            'Matchup_Count': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add a column to indicate the current season and week\n",
    "        team_home_away_impact['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "        team_home_away_impact['Season'] = season\n",
    "        team_home_away_impact['Week'] = week\n",
    "\n",
    "        # Round the aggregated values to 3 decimals\n",
    "        team_home_away_impact = team_home_away_impact.round({'Home_Avg_Diff': 3, 'Away_Avg_Diff': 3, 'Home_Impact': 3, 'Away_Impact': 3})\n",
    "        \n",
    "        # Append the current week's team-level impacts to the overall list\n",
    "        all_team_impacts.append(team_home_away_impact)\n",
    "\n",
    "# Combine all weekly impacts into a single DataFrame\n",
    "final_team_impact_df = pd.concat(all_team_impacts, ignore_index=True)\n",
    "\n",
    "# Print or store the final aggregated team-level impacts\n",
    "print(final_team_impact_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Team', 'Home_Avg_Diff', 'Away_Avg_Diff', 'Home_Impact', 'Away_Impact',\n",
      "       'Matchup_Count', 'SeasonWeek', 'Season', 'Week'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(final_team_impact_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create additional features and interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Day', 'Date', 'Time', 'Winner', 'LoserIsHome', 'Loser', 'PtsW', 'PtsL',\n",
      "       'YdsW', 'TOW', 'YdsL', 'TOL', 'season', 'week', 'Winner Abbr',\n",
      "       'Loser Abbr', 'Home Team', 'Away Team', 'Home Score', 'Away Score',\n",
      "       'Winner Yds', 'Loser Yds', 'Margin Yds', 'Winner TO', 'Loser TO',\n",
      "       'Margin TO', 'Margin Pts', 'Total Pts', 'Margin Pct',\n",
      "       'home_team_winner', 'away_win_bonus', 'DateTime',\n",
      "       'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', 'Home_DefenseRank',\n",
      "       'Home_OffenseRank', 'Home_ScoreRank', 'Week', 'Away_DefenseRank',\n",
      "       'Away_OffenseRank', 'Away_ScoreRank', 'Spread', 'Delta_OffenseRank',\n",
      "       'Ratio_OffenseRank', 'Delta_DefenseRank', 'Ratio_DefenseRank',\n",
      "       'Delta_ScoreRank', 'Ratio_ScoreRank', 'intTerm1', 'intTerm2',\n",
      "       'intTerm3', 'intTerm4', 'quadTerm1', 'quadTerm2', 'quadTerm3',\n",
      "       'quadTerm4', 'HomeStrength', 'AwayStrength'],\n",
      "      dtype='object')\n",
      "2211\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the combined_rankings dataframe to create offensive and defensive rank features\n",
    "rankings = final_rankings_df.pivot(index=['Team', 'SeasonWeek', 'Season', 'Week'], columns='Type', values='Ranking').reset_index()\n",
    "rankings.rename(columns={'Offense': 'OffenseRank', 'Defense': 'DefenseRank', 'Score': 'ScoreRank'}, inplace=True)\n",
    "\n",
    "# Adjust rankings to use the prior week's data\n",
    "rankings['Week'] += 1\n",
    "\n",
    "# Merge the rankings with game results to create the feature set\n",
    "def merge_rankings(df, team_column, prefix):\n",
    "    return df.merge(rankings, left_on=[team_column, 'season', 'week'], right_on=['Team', 'Season', 'Week'], how='left') \\\n",
    "             .rename(columns={'OffenseRank': f'{prefix}_OffenseRank',\n",
    "                              'DefenseRank': f'{prefix}_DefenseRank',\n",
    "                              'ScoreRank': f'{prefix}_ScoreRank'})\n",
    "\n",
    "merged_df = merge_rankings(df_results, 'Home Team', 'Home')\n",
    "merged_df = merge_rankings(merged_df, 'Away Team', 'Away')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(columns=['Unnamed: 0', 'Team_x', 'Season_x', 'SeasonWeek_x', 'Week_x',\n",
    "                        'Team_y', 'Season_y', 'SeasonWeek_y', 'Week_y'], inplace=True)\n",
    "\n",
    "# Filter to only games where rankings exist for both teams\n",
    "merged_df.dropna(subset=['Home_OffenseRank', 'Home_DefenseRank', 'Away_OffenseRank', 'Away_DefenseRank'], inplace=True)\n",
    "\n",
    "# Create target variable (spread)\n",
    "merged_df['Spread'] = merged_df.apply(lambda row: row['PtsW'] - row['PtsL']\n",
    "                                      if row['Home Team'] == row['Winner Abbr']\n",
    "                                      else row['PtsL'] - row['PtsW'], axis=1)\n",
    "\n",
    "# Create feature deltas and ratios\n",
    "rank_features = ['OffenseRank', 'DefenseRank', 'ScoreRank']\n",
    "for feature in rank_features:\n",
    "    merged_df[f'Delta_{feature}'] = merged_df[f'Home_{feature}'] - merged_df[f'Away_{feature}']\n",
    "    merged_df[f'Ratio_{feature}'] = merged_df[f'Home_{feature}'] / (merged_df[f'Away_{feature}'] + 1e-5)\n",
    "\n",
    "# Create interaction and quadratic terms\n",
    "interaction_terms = [\n",
    "    ('Home_OffenseRank', 'Away_DefenseRank'),\n",
    "    ('Away_OffenseRank', 'Home_DefenseRank'),\n",
    "    ('Home_OffenseRank', 'Away_OffenseRank'),\n",
    "    ('Away_DefenseRank', 'Home_DefenseRank')\n",
    "]\n",
    "for i, (col1, col2) in enumerate(interaction_terms, 1):\n",
    "    merged_df[f'intTerm{i}'] = merged_df[col1] * merged_df[col2]\n",
    "\n",
    "quadratic_terms = [\n",
    "    'Home_OffenseRank', 'Away_OffenseRank', 'Home_DefenseRank', 'Away_DefenseRank'\n",
    "]\n",
    "for i, col in enumerate(quadratic_terms, 1):\n",
    "    merged_df[f'quadTerm{i}'] = merged_df[col] ** 2\n",
    "\n",
    "# Create strength features\n",
    "merged_df['HomeStrength'] = merged_df['Home_OffenseRank'] + merged_df['Home_DefenseRank'] + merged_df['Home_ScoreRank']\n",
    "merged_df['AwayStrength'] = merged_df['Away_OffenseRank'] + merged_df['Away_DefenseRank'] + merged_df['Away_ScoreRank']\n",
    "\n",
    "print(merged_df.columns)\n",
    "print(len(merged_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Day        Date    Time                 Winner LoserIsHome  \\\n",
      "0  Thu  2024-10-03  8:15PM        Atlanta Falcons         NaN   \n",
      "1  Sun  2024-10-06  9:30AM      Minnesota Vikings         NaN   \n",
      "2  Sun  2024-10-06  1:00PM       Baltimore Ravens           @   \n",
      "3  Sun  2024-10-06  1:00PM         Houston Texans         NaN   \n",
      "4  Sun  2024-10-06  1:00PM  Washington Commanders         NaN   \n",
      "\n",
      "                  Loser  PtsW  PtsL   YdsW  TOW  ...  intTerm4  quadTerm1  \\\n",
      "0  Tampa Bay Buccaneers  36.0  30.0  550.0  1.0  ...  0.001417   0.000077   \n",
      "1         New York Jets  23.0  17.0  253.0  2.0  ...  0.000536   0.013266   \n",
      "2    Cincinnati Bengals  41.0  38.0  520.0  1.0  ...  0.000572   0.000314   \n",
      "3         Buffalo Bills  23.0  20.0  425.0  2.0  ...  0.000345   0.000867   \n",
      "4      Cleveland Browns  34.0  13.0  434.0  2.0  ...  0.000335   0.000420   \n",
      "\n",
      "   quadTerm2  quadTerm3 quadTerm4 HomeStrength AwayStrength Home_Impact  \\\n",
      "0   0.002313   0.001724  0.001164      0.06953      0.18686      -5.500   \n",
      "1   0.006780   0.000152  0.001891      0.18464      0.13481      -0.472   \n",
      "2   0.000549   0.002098  0.000156      0.06703      0.04481       0.187   \n",
      "3   0.000140   0.001423  0.000084      0.10086      0.02682       0.556   \n",
      "4   0.000029   0.000145  0.000774      0.04431      0.03593     -15.556   \n",
      "\n",
      "   Away_Impact    GameType  \n",
      "0       -8.278  Historical  \n",
      "1       14.083  Historical  \n",
      "2        2.861  Historical  \n",
      "3      -21.972  Historical  \n",
      "4       -0.000  Historical  \n",
      "\n",
      "[5 rows x 61 columns]\n",
      "2211 2211\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Merge with home/away impact to create the feature set\n",
    "adv_df = pd.merge(\n",
    "    merged_df,\n",
    "    final_team_impact_df,\n",
    "    left_on=['Home Team', 'season', 'week'],\n",
    "    right_on=['Team', 'Season', 'Week'],\n",
    "    suffixes=('', '_Home'), how='left'\n",
    ")\n",
    "\n",
    "\n",
    "adv_df = pd.merge(\n",
    "    adv_df,\n",
    "    final_team_impact_df,\n",
    "    left_on=['Away Team', 'season', 'week'],\n",
    "    right_on=['Team', 'Season', 'Week'],\n",
    "    suffixes=('', '_Away'), how='left'\n",
    ")\n",
    "\n",
    "\n",
    "# Drop unnecessary columns\n",
    "adv_df.drop(columns=['Team', 'Home_Avg_Diff',\n",
    "            'Away_Avg_Diff', 'Away_Impact', 'Matchup_Count',\n",
    "            'SeasonWeek', 'Season', 'Week_Home', 'Team_Away', 'Home_Avg_Diff_Away',\n",
    "            'Away_Avg_Diff_Away', 'Home_Impact_Away', \n",
    "            'Matchup_Count_Away', 'SeasonWeek_Away', 'Season_Away', 'Week_Away'], inplace=True)\n",
    "\n",
    "adv_df.rename(columns={'Away_Impact_Away': 'Away_Impact'}, inplace=True)\n",
    "adv_df['Home_Impact'] = adv_df['Home_Impact'].fillna(0)\n",
    "adv_df['Away_Impact'] = adv_df['Away_Impact'].fillna(0)\n",
    "\n",
    "# Create variable for historical and future games\n",
    "adv_df['GameType'] = adv_df.apply(lambda row: \"Historical\" \n",
    "                                      if not pd.isna(row['Margin Yds'])\n",
    "                                      else \"Future\", axis=1)\n",
    "\n",
    "print(adv_df.head())\n",
    "print(len(merged_df), len(adv_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Day', 'Date', 'Time', 'Winner', 'LoserIsHome', 'Loser', 'PtsW', 'PtsL',\n",
      "       'YdsW', 'TOW', 'YdsL', 'TOL', 'season', 'week', 'Winner Abbr',\n",
      "       'Loser Abbr', 'Home Team', 'Away Team', 'Home Score', 'Away Score',\n",
      "       'Winner Yds', 'Loser Yds', 'Margin Yds', 'Winner TO', 'Loser TO',\n",
      "       'Margin TO', 'Margin Pts', 'Total Pts', 'Margin Pct',\n",
      "       'home_team_winner', 'away_win_bonus', 'DateTime',\n",
      "       'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', 'Home_DefenseRank',\n",
      "       'Home_OffenseRank', 'Home_ScoreRank', 'Week', 'Away_DefenseRank',\n",
      "       'Away_OffenseRank', 'Away_ScoreRank', 'Spread', 'Delta_OffenseRank',\n",
      "       'Ratio_OffenseRank', 'Delta_DefenseRank', 'Ratio_DefenseRank',\n",
      "       'Delta_ScoreRank', 'Ratio_ScoreRank', 'intTerm1', 'intTerm2',\n",
      "       'intTerm3', 'intTerm4', 'quadTerm1', 'quadTerm2', 'quadTerm3',\n",
      "       'quadTerm4', 'HomeStrength', 'AwayStrength', 'Home_Impact',\n",
      "       'Away_Impact', 'GameType'],\n",
      "      dtype='object')\n",
      "2199 12\n"
     ]
    }
   ],
   "source": [
    "feature_df = adv_df\n",
    "print(feature_df.columns)\n",
    "feature_df.to_csv('../data/nfl_games_pfr_features.csv')\n",
    "\n",
    "#Separate played and upcoming games\n",
    "merged_played = feature_df[~feature_df['Margin Yds'].isna()]\n",
    "merged_upcoming = feature_df[feature_df['Margin Yds'].isna()]\n",
    "print(len(merged_played),len(merged_upcoming))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Delta_ScoreRank  Ratio_ScoreRank\n",
      "count      2199.000000      2199.000000\n",
      "mean          0.000275         2.152297\n",
      "std           0.041654         3.646089\n",
      "min          -0.190230         0.013996\n",
      "25%          -0.017135         0.459149\n",
      "50%           0.000000         0.999616\n",
      "75%           0.017925         2.221810\n",
      "max           0.219740        55.795511\n",
      "      Delta_ScoreRank  Ratio_ScoreRank\n",
      "0.05        -0.068186         0.117328\n",
      "0.10        -0.044448         0.189477\n",
      "0.15        -0.031521         0.272978\n",
      "0.20        -0.023382         0.361712\n",
      "0.25        -0.017135         0.459149\n",
      "0.30        -0.012044         0.550076\n",
      "0.35        -0.008400         0.649963\n",
      "0.40        -0.005316         0.743395\n",
      "0.45        -0.002509         0.858579\n",
      "0.50         0.000000         0.999616\n",
      "0.55         0.002220         1.143941\n",
      "0.60         0.005230         1.322784\n",
      "0.65         0.008540         1.546106\n",
      "0.70         0.012580         1.838846\n",
      "0.75         0.017925         2.221810\n",
      "0.80         0.024472         2.703818\n",
      "0.85         0.032990         3.602244\n",
      "0.90         0.045768         5.146693\n",
      "0.95         0.067127         8.182584\n"
     ]
    }
   ],
   "source": [
    "# Basic summary statistics for all numerical columns\n",
    "print(merged_played[['Delta_ScoreRank','Ratio_ScoreRank']].describe())\n",
    "\n",
    "# Calculate percentiles at each 10th percentile (0.1, 0.2, ..., 0.9)\n",
    "percentiles = [i / 20 for i in range(1, 20)]\n",
    "print(merged_played[['Delta_ScoreRank','Ratio_ScoreRank']].quantile(percentiles))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
