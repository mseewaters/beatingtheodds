{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive models for NFL games to enable spread betting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic python packages\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score,  r2_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression model packages\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "df_results = pd.read_csv('../data/nfl_games_pfr.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create rankings using pagerank from nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Graph Functions\n",
    "def create_graph(game_data, week_num):\n",
    "    G = nx.DiGraph()\n",
    "    margin_totals = defaultdict(float)\n",
    "    game_counts = defaultdict(int)\n",
    "    \n",
    "    # Iterate over each game result\n",
    "    for _, row in game_data.iterrows():\n",
    "        winner = row['winner']\n",
    "        loser = row['loser']\n",
    "        week = row['week']\n",
    "        margin = row['margin']\n",
    "\n",
    "        key = (loser, winner)\n",
    "        margin_totals[key] += margin\n",
    "        game_counts[key] += 1\n",
    "\n",
    "    # Add edges with average margin as weight\n",
    "    for (loser, winner), total_margin in margin_totals.items():\n",
    "        avg_margin = total_margin / game_counts[(loser, winner)]\n",
    "        G.add_edge(loser, winner, weight=avg_margin)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Function to calculate rankings based on the weighted graph\n",
    "def calculate_rankings(graph):\n",
    "    # Calculate PageRank with weights\n",
    "    return pd.DataFrame(nx.pagerank(graph, alpha=0.92, weight='weight').items(), columns=['Team', 'Ranking'])\n",
    "\n",
    "# Function to generate rankings for each season and week\n",
    "def generate_rankings(df_filtered, feature_type):\n",
    "    # Initialize an empty list to store rankings DataFrames\n",
    "    ranking_dfs = []\n",
    "\n",
    "    # Loop over each distinct season in the dataset\n",
    "    for season in df_filtered['season'].unique():\n",
    "        # Filter the game data for the current season\n",
    "        season_data = df_filtered[df_filtered['season'] == season]\n",
    "        \n",
    "        # Loop over the weeks for this season\n",
    "        for week in range(2, season_data['week'].max() + 1):\n",
    "            # Filter the game data up to the current week for the current season\n",
    "            filtered_data = season_data[season_data['week'] <= week]\n",
    "            \n",
    "            # Create the directed graph for the current season and weeks\n",
    "            G = create_graph(filtered_data, week)\n",
    "            \n",
    "            # Calculate the rankings based on the weighted graph\n",
    "            rankings = calculate_rankings(G)\n",
    "\n",
    "            # Round the rankings to 4 decimal places\n",
    "            rankings['Ranking'] = rankings['Ranking'].round(5)\n",
    "            \n",
    "            # Add columns indicating the season and week, with a leading zero for weeks\n",
    "            rankings['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "            rankings['Season'] = season\n",
    "            rankings['Week'] = week\n",
    "            rankings['Type'] = feature_type\n",
    "            \n",
    "            # Append the rankings to the list\n",
    "            ranking_dfs.append(rankings)\n",
    "    \n",
    "    # Concatenate all rankings DataFrames into a single DataFrame\n",
    "    return pd.concat(ranking_dfs)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.01344   2024_W02    2024     2  Offense\n",
      "1  BAL  0.03328   2024_W02    2024     2  Offense\n",
      "2  PHI  0.01344   2024_W02    2024     2  Offense\n",
      "3   GB  0.01900   2024_W02    2024     2  Offense\n",
      "4  ATL  0.02375   2024_W02    2024     2  Offense\n",
      "4832\n"
     ]
    }
   ],
   "source": [
    "### OFFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_offense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Yds','Loser Yds','Margin Yds']]\n",
    "df_offense = df_offense.rename(columns={'Winner Yds':'winner', 'Loser Yds':'loser','Margin Yds':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "final_offense_rankings_df = generate_rankings(df_offense, \"Offense\")\n",
    "print(final_offense_rankings_df.head())\n",
    "print(len(final_offense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0  BAL  0.01844   2024_W02    2024     2  Defense\n",
      "1   KC  0.05100   2024_W02    2024     2  Defense\n",
      "2   GB  0.01844   2024_W02    2024     2  Defense\n",
      "3  PHI  0.05324   2024_W02    2024     2  Defense\n",
      "4  PIT  0.01844   2024_W02    2024     2  Defense\n",
      "4832\n"
     ]
    }
   ],
   "source": [
    "### DEFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_defense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner TO','Loser TO','Margin TO']]\n",
    "df_defense = df_defense.rename(columns={'Winner TO':'winner', 'Loser TO':'loser','Margin TO':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "final_defense_rankings_df = generate_rankings(df_defense, \"Defense\")\n",
    "print(final_defense_rankings_df.head())\n",
    "print(len(final_defense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week   Type\n",
      "0  BAL  0.01573   2024_W02    2024     2  Score\n",
      "1   KC  0.02793   2024_W02    2024     2  Score\n",
      "2   GB  0.02658   2024_W02    2024     2  Score\n",
      "3  PHI  0.04018   2024_W02    2024     2  Score\n",
      "4  ATL  0.05270   2024_W02    2024     2  Score\n",
      "4832\n"
     ]
    }
   ],
   "source": [
    "### SCORE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_score = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Abbr','Loser Abbr','Margin Pts']]\n",
    "df_score = df_score.rename(columns={'Winner Abbr':'winner', 'Loser Abbr':'loser', 'Margin Pts':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "final_score_rankings_df = generate_rankings(df_score, \"Score\")\n",
    "print(final_score_rankings_df.head())\n",
    "print(len(final_score_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.01344   2024_W02    2024     2  Offense\n",
      "1  BAL  0.03328   2024_W02    2024     2  Offense\n",
      "2  PHI  0.01344   2024_W02    2024     2  Offense\n",
      "3   GB  0.01900   2024_W02    2024     2  Offense\n",
      "4  ATL  0.02375   2024_W02    2024     2  Offense\n",
      "14496\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all feature rankings into a single DataFrame\n",
    "final_rankings_df = pd.concat([final_offense_rankings_df, final_score_rankings_df, final_defense_rankings_df])\n",
    "print(final_rankings_df.head())\n",
    "print(len(final_rankings_df))\n",
    "final_rankings_df.to_csv('../data/nfl_rankings_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create additional features and interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Day', 'Date', 'Time', 'Winner', 'LoserIsHome', 'Loser', 'PtsW', 'PtsL',\n",
      "       'YdsW', 'TOW', 'YdsL', 'TOL', 'season', 'week', 'Winner Abbr',\n",
      "       'Loser Abbr', 'Home Team', 'Away Team', 'Winner Yds', 'Loser Yds',\n",
      "       'Margin Yds', 'Winner TO', 'Loser TO', 'Margin TO', 'Margin Pts',\n",
      "       'Total Pts', 'Margin Pct', 'home_team_winner', 'away_win_bonus',\n",
      "       'Home_DefenseRank', 'Home_OffenseRank', 'Home_ScoreRank', 'Week',\n",
      "       'Away_DefenseRank', 'Away_OffenseRank', 'Away_ScoreRank', 'Spread',\n",
      "       'Delta_OffenseRank', 'Ratio_OffenseRank', 'Delta_DefenseRank',\n",
      "       'Ratio_DefenseRank', 'Delta_ScoreRank', 'Ratio_ScoreRank', 'intTerm1',\n",
      "       'intTerm2', 'intTerm3', 'intTerm4', 'quadTerm1', 'quadTerm2',\n",
      "       'quadTerm3', 'quadTerm4', 'HomeStrength', 'AwayStrength', 'GameType'],\n",
      "      dtype='object')\n",
      "2097 13\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the combined_rankings dataframe to create offensive and defensive rank features\n",
    "rankings = final_rankings_df.pivot(index=['Team', 'SeasonWeek', 'Season', 'Week'], columns='Type', values='Ranking').reset_index()\n",
    "rankings.rename(columns={'Offense': 'OffenseRank', 'Defense': 'DefenseRank', 'Score': 'ScoreRank'}, inplace=True)\n",
    "\n",
    "# Adjust rankings to use the prior week's data\n",
    "rankings['Week'] += 1\n",
    "\n",
    "# Merge the rankings with game results to create the feature set\n",
    "def merge_rankings(df, team_column, prefix):\n",
    "    return df.merge(rankings, left_on=[team_column, 'season', 'week'], right_on=['Team', 'Season', 'Week'], how='left') \\\n",
    "             .rename(columns={'OffenseRank': f'{prefix}_OffenseRank',\n",
    "                              'DefenseRank': f'{prefix}_DefenseRank',\n",
    "                              'ScoreRank': f'{prefix}_ScoreRank'})\n",
    "\n",
    "merged_df = merge_rankings(df_results, 'Home Team', 'Home')\n",
    "merged_df = merge_rankings(merged_df, 'Away Team', 'Away')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(columns=['Unnamed: 0', 'Team_x', 'Season_x', 'SeasonWeek_x', 'Week_x',\n",
    "                        'Team_y', 'Season_y', 'SeasonWeek_y', 'Week_y'], inplace=True)\n",
    "\n",
    "# Filter to only games where rankings exist for both teams\n",
    "merged_df.dropna(subset=['Home_OffenseRank', 'Home_DefenseRank', 'Away_OffenseRank', 'Away_DefenseRank'], inplace=True)\n",
    "\n",
    "# Create target variable (spread)\n",
    "merged_df['Spread'] = merged_df.apply(lambda row: row['PtsW'] - row['PtsL']\n",
    "                                      if row['Home Team'] == row['Winner Abbr']\n",
    "                                      else row['PtsL'] - row['PtsW'], axis=1)\n",
    "\n",
    "# Create feature deltas and ratios\n",
    "rank_features = ['OffenseRank', 'DefenseRank', 'ScoreRank']\n",
    "for feature in rank_features:\n",
    "    merged_df[f'Delta_{feature}'] = merged_df[f'Home_{feature}'] - merged_df[f'Away_{feature}']\n",
    "    merged_df[f'Ratio_{feature}'] = merged_df[f'Home_{feature}'] / (merged_df[f'Away_{feature}'] + 1e-5)\n",
    "\n",
    "# Create interaction and quadratic terms\n",
    "interaction_terms = [\n",
    "    ('Home_OffenseRank', 'Away_DefenseRank'),\n",
    "    ('Away_OffenseRank', 'Home_DefenseRank'),\n",
    "    ('Home_OffenseRank', 'Away_OffenseRank'),\n",
    "    ('Away_DefenseRank', 'Home_DefenseRank')\n",
    "]\n",
    "for i, (col1, col2) in enumerate(interaction_terms, 1):\n",
    "    merged_df[f'intTerm{i}'] = merged_df[col1] * merged_df[col2]\n",
    "\n",
    "quadratic_terms = [\n",
    "    'Home_OffenseRank', 'Away_OffenseRank', 'Home_DefenseRank', 'Away_DefenseRank'\n",
    "]\n",
    "for i, col in enumerate(quadratic_terms, 1):\n",
    "    merged_df[f'quadTerm{i}'] = merged_df[col] ** 2\n",
    "\n",
    "# Create strength features\n",
    "merged_df['HomeStrength'] = merged_df['Home_OffenseRank'] + merged_df['Home_DefenseRank'] + merged_df['Home_ScoreRank']\n",
    "merged_df['AwayStrength'] = merged_df['Away_OffenseRank'] + merged_df['Away_DefenseRank'] + merged_df['Away_ScoreRank']\n",
    "\n",
    "# Create variable for historical and future games\n",
    "merged_df['GameType'] = merged_df.apply(lambda row: \"Historical\" \n",
    "                                      if not pd.isna(row['Margin Yds'])\n",
    "                                      else \"Future\", axis=1)\n",
    "\n",
    "print(merged_df.columns)\n",
    "merged_df.to_csv('../data/nfl_games_pfr_features.csv')\n",
    "\n",
    "#Separate played and upcoming games\n",
    "merged_played = merged_df[~merged_df['Margin Yds'].isna()]\n",
    "merged_upcoming = merged_df[merged_df['Margin Yds'].isna()]\n",
    "print(len(merged_played),len(merged_upcoming))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and basic feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Define features and target\n",
    "feature_sets = [\n",
    "    merged_played[['Home_ScoreRank','Away_ScoreRank']], \n",
    "    merged_played[['Delta_ScoreRank']],\n",
    "    merged_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank', 'Away_DefenseRank','Away_ScoreRank']],\n",
    "    merged_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank']],\n",
    "    merged_played[['Home_OffenseRank', 'Home_DefenseRank','Away_OffenseRank', 'Away_DefenseRank']],\n",
    "    merged_played[['Delta_OffenseRank','Delta_DefenseRank']],\n",
    "    merged_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank',\\\n",
    "               'Away_DefenseRank','Away_ScoreRank', 'Delta_ScoreRank','Delta_OffenseRank',\\\n",
    "                'Delta_DefenseRank', 'Ratio_ScoreRank', 'Ratio_OffenseRank', 'Ratio_DefenseRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4', \\\n",
    "                'HomeStrength', 'AwayStrength']],\n",
    "    merged_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4']],\n",
    "    merged_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4']],\n",
    "    merged_played[['Delta_ScoreRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4']],\n",
    "    scaler.fit_transform(merged_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank', \\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4']]),\n",
    "    scaler.fit_transform(merged_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank', \\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4']])\n",
    "\n",
    "]\n",
    "y = merged_played['Spread']\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    ('LM', LinearRegression()),\n",
    "    ('LMnoINT', LinearRegression(fit_intercept=False)),\n",
    "    ('Ridge0.05', Ridge(alpha=0.05)),\n",
    "    ('Ridge0.1', Ridge(alpha=0.1)),\n",
    "    ('Ridge0.5', Ridge(alpha=0.5)),  # You can tune the alpha parameter\n",
    "    ('XGBoostBase', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('XGBoost150', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('XGBoost5', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=5, random_state=42)),\n",
    "    ('XGBoost0.5', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.05, max_depth=3, random_state=42)),\n",
    "    ('RF50', RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)),\n",
    "    ('RF10', RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)),\n",
    "    ('SVR', SVR(kernel='rbf', C=1.0, epsilon=0.1)),\n",
    "    ('SVRlin', SVR(kernel='linear', C=1.0, epsilon=0.1)),\n",
    "    ('kNN5', KNeighborsRegressor(n_neighbors=5)),\n",
    "    ('kNN17', KNeighborsRegressor(n_neighbors=17))\n",
    "]\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: LM with feature set 1\n",
      "Evaluating model: LMnoINT with feature set 1\n",
      "Evaluating model: Ridge0.05 with feature set 1\n",
      "Evaluating model: Ridge0.1 with feature set 1\n",
      "Evaluating model: Ridge0.5 with feature set 1\n",
      "Evaluating model: XGBoostBase with feature set 1\n",
      "Evaluating model: XGBoost150 with feature set 1\n",
      "Evaluating model: XGBoost5 with feature set 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\see_w\\AppData\\Local\\Temp\\ipykernel_17132\\568564045.py:47: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  results = pd.concat([results, new_result], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: XGBoost0.5 with feature set 1\n",
      "Evaluating model: RF50 with feature set 1\n",
      "Evaluating model: RF10 with feature set 1\n",
      "Evaluating model: SVR with feature set 1\n",
      "Evaluating model: SVRlin with feature set 1\n",
      "Evaluating model: kNN5 with feature set 1\n",
      "Evaluating model: kNN17 with feature set 1\n",
      "Evaluating model: LM with feature set 2\n",
      "Evaluating model: LMnoINT with feature set 2\n",
      "Evaluating model: Ridge0.05 with feature set 2\n",
      "Evaluating model: Ridge0.1 with feature set 2\n",
      "Evaluating model: Ridge0.5 with feature set 2\n",
      "Evaluating model: XGBoostBase with feature set 2\n",
      "Evaluating model: XGBoost150 with feature set 2\n",
      "Evaluating model: XGBoost5 with feature set 2\n",
      "Evaluating model: XGBoost0.5 with feature set 2\n",
      "Evaluating model: RF50 with feature set 2\n",
      "Evaluating model: RF10 with feature set 2\n",
      "Evaluating model: SVR with feature set 2\n",
      "Evaluating model: SVRlin with feature set 2\n",
      "Evaluating model: kNN5 with feature set 2\n",
      "Evaluating model: kNN17 with feature set 2\n",
      "Evaluating model: LM with feature set 3\n",
      "Evaluating model: LMnoINT with feature set 3\n",
      "Evaluating model: Ridge0.05 with feature set 3\n",
      "Evaluating model: Ridge0.1 with feature set 3\n",
      "Evaluating model: Ridge0.5 with feature set 3\n",
      "Evaluating model: XGBoostBase with feature set 3\n",
      "Evaluating model: XGBoost150 with feature set 3\n",
      "Evaluating model: XGBoost5 with feature set 3\n",
      "Evaluating model: XGBoost0.5 with feature set 3\n",
      "Evaluating model: RF50 with feature set 3\n",
      "Evaluating model: RF10 with feature set 3\n",
      "Evaluating model: SVR with feature set 3\n",
      "Evaluating model: SVRlin with feature set 3\n",
      "Evaluating model: kNN5 with feature set 3\n",
      "Evaluating model: kNN17 with feature set 3\n",
      "Evaluating model: LM with feature set 4\n",
      "Evaluating model: LMnoINT with feature set 4\n",
      "Evaluating model: Ridge0.05 with feature set 4\n",
      "Evaluating model: Ridge0.1 with feature set 4\n",
      "Evaluating model: Ridge0.5 with feature set 4\n",
      "Evaluating model: XGBoostBase with feature set 4\n",
      "Evaluating model: XGBoost150 with feature set 4\n",
      "Evaluating model: XGBoost5 with feature set 4\n",
      "Evaluating model: XGBoost0.5 with feature set 4\n",
      "Evaluating model: RF50 with feature set 4\n",
      "Evaluating model: RF10 with feature set 4\n",
      "Evaluating model: SVR with feature set 4\n",
      "Evaluating model: SVRlin with feature set 4\n",
      "Evaluating model: kNN5 with feature set 4\n",
      "Evaluating model: kNN17 with feature set 4\n",
      "Evaluating model: LM with feature set 5\n",
      "Evaluating model: LMnoINT with feature set 5\n",
      "Evaluating model: Ridge0.05 with feature set 5\n",
      "Evaluating model: Ridge0.1 with feature set 5\n",
      "Evaluating model: Ridge0.5 with feature set 5\n",
      "Evaluating model: XGBoostBase with feature set 5\n",
      "Evaluating model: XGBoost150 with feature set 5\n",
      "Evaluating model: XGBoost5 with feature set 5\n",
      "Evaluating model: XGBoost0.5 with feature set 5\n",
      "Evaluating model: RF50 with feature set 5\n",
      "Evaluating model: RF10 with feature set 5\n",
      "Evaluating model: SVR with feature set 5\n",
      "Evaluating model: SVRlin with feature set 5\n",
      "Evaluating model: kNN5 with feature set 5\n",
      "Evaluating model: kNN17 with feature set 5\n",
      "Evaluating model: LM with feature set 6\n",
      "Evaluating model: LMnoINT with feature set 6\n",
      "Evaluating model: Ridge0.05 with feature set 6\n",
      "Evaluating model: Ridge0.1 with feature set 6\n",
      "Evaluating model: Ridge0.5 with feature set 6\n",
      "Evaluating model: XGBoostBase with feature set 6\n",
      "Evaluating model: XGBoost150 with feature set 6\n",
      "Evaluating model: XGBoost5 with feature set 6\n",
      "Evaluating model: XGBoost0.5 with feature set 6\n",
      "Evaluating model: RF50 with feature set 6\n",
      "Evaluating model: RF10 with feature set 6\n",
      "Evaluating model: SVR with feature set 6\n",
      "Evaluating model: SVRlin with feature set 6\n",
      "Evaluating model: kNN5 with feature set 6\n",
      "Evaluating model: kNN17 with feature set 6\n",
      "Evaluating model: LM with feature set 7\n",
      "Evaluating model: LMnoINT with feature set 7\n",
      "Evaluating model: Ridge0.05 with feature set 7\n",
      "Evaluating model: Ridge0.1 with feature set 7\n",
      "Evaluating model: Ridge0.5 with feature set 7\n",
      "Evaluating model: XGBoostBase with feature set 7\n",
      "Evaluating model: XGBoost150 with feature set 7\n",
      "Evaluating model: XGBoost5 with feature set 7\n",
      "Evaluating model: XGBoost0.5 with feature set 7\n",
      "Evaluating model: RF50 with feature set 7\n",
      "Evaluating model: RF10 with feature set 7\n",
      "Evaluating model: SVR with feature set 7\n",
      "Evaluating model: SVRlin with feature set 7\n",
      "Evaluating model: kNN5 with feature set 7\n",
      "Evaluating model: kNN17 with feature set 7\n",
      "Evaluating model: LM with feature set 8\n",
      "Evaluating model: LMnoINT with feature set 8\n",
      "Evaluating model: Ridge0.05 with feature set 8\n",
      "Evaluating model: Ridge0.1 with feature set 8\n",
      "Evaluating model: Ridge0.5 with feature set 8\n",
      "Evaluating model: XGBoostBase with feature set 8\n",
      "Evaluating model: XGBoost150 with feature set 8\n",
      "Evaluating model: XGBoost5 with feature set 8\n",
      "Evaluating model: XGBoost0.5 with feature set 8\n",
      "Evaluating model: RF50 with feature set 8\n",
      "Evaluating model: RF10 with feature set 8\n",
      "Evaluating model: SVR with feature set 8\n",
      "Evaluating model: SVRlin with feature set 8\n",
      "Evaluating model: kNN5 with feature set 8\n",
      "Evaluating model: kNN17 with feature set 8\n",
      "Evaluating model: LM with feature set 9\n",
      "Evaluating model: LMnoINT with feature set 9\n",
      "Evaluating model: Ridge0.05 with feature set 9\n",
      "Evaluating model: Ridge0.1 with feature set 9\n",
      "Evaluating model: Ridge0.5 with feature set 9\n",
      "Evaluating model: XGBoostBase with feature set 9\n",
      "Evaluating model: XGBoost150 with feature set 9\n",
      "Evaluating model: XGBoost5 with feature set 9\n",
      "Evaluating model: XGBoost0.5 with feature set 9\n",
      "Evaluating model: RF50 with feature set 9\n",
      "Evaluating model: RF10 with feature set 9\n",
      "Evaluating model: SVR with feature set 9\n",
      "Evaluating model: SVRlin with feature set 9\n",
      "Evaluating model: kNN5 with feature set 9\n",
      "Evaluating model: kNN17 with feature set 9\n",
      "Evaluating model: LM with feature set 10\n",
      "Evaluating model: LMnoINT with feature set 10\n",
      "Evaluating model: Ridge0.05 with feature set 10\n",
      "Evaluating model: Ridge0.1 with feature set 10\n",
      "Evaluating model: Ridge0.5 with feature set 10\n",
      "Evaluating model: XGBoostBase with feature set 10\n",
      "Evaluating model: XGBoost150 with feature set 10\n",
      "Evaluating model: XGBoost5 with feature set 10\n",
      "Evaluating model: XGBoost0.5 with feature set 10\n",
      "Evaluating model: RF50 with feature set 10\n",
      "Evaluating model: RF10 with feature set 10\n",
      "Evaluating model: SVR with feature set 10\n",
      "Evaluating model: SVRlin with feature set 10\n",
      "Evaluating model: kNN5 with feature set 10\n",
      "Evaluating model: kNN17 with feature set 10\n",
      "Evaluating model: LM with feature set 11\n",
      "Evaluating model: LMnoINT with feature set 11\n",
      "Evaluating model: Ridge0.05 with feature set 11\n",
      "Evaluating model: Ridge0.1 with feature set 11\n",
      "Evaluating model: Ridge0.5 with feature set 11\n",
      "Evaluating model: XGBoostBase with feature set 11\n",
      "Evaluating model: XGBoost150 with feature set 11\n",
      "Evaluating model: XGBoost5 with feature set 11\n",
      "Evaluating model: XGBoost0.5 with feature set 11\n",
      "Evaluating model: RF50 with feature set 11\n",
      "Evaluating model: RF10 with feature set 11\n",
      "Evaluating model: SVR with feature set 11\n",
      "Evaluating model: SVRlin with feature set 11\n",
      "Evaluating model: kNN5 with feature set 11\n",
      "Evaluating model: kNN17 with feature set 11\n",
      "Evaluating model: LM with feature set 12\n",
      "Evaluating model: LMnoINT with feature set 12\n",
      "Evaluating model: Ridge0.05 with feature set 12\n",
      "Evaluating model: Ridge0.1 with feature set 12\n",
      "Evaluating model: Ridge0.5 with feature set 12\n",
      "Evaluating model: XGBoostBase with feature set 12\n",
      "Evaluating model: XGBoost150 with feature set 12\n",
      "Evaluating model: XGBoost5 with feature set 12\n",
      "Evaluating model: XGBoost0.5 with feature set 12\n",
      "Evaluating model: RF50 with feature set 12\n",
      "Evaluating model: RF10 with feature set 12\n",
      "Evaluating model: SVR with feature set 12\n",
      "Evaluating model: SVRlin with feature set 12\n",
      "Evaluating model: kNN5 with feature set 12\n",
      "Evaluating model: kNN17 with feature set 12\n"
     ]
    }
   ],
   "source": [
    "# DataFrame to store results\n",
    "results = pd.DataFrame(columns=['Model', 'Feature_Set', 'MSE', 'Accuracy'])\n",
    "\n",
    "# Iterate over feature sets and models\n",
    "for i, X in enumerate(feature_sets):\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    for model_name, model in models:\n",
    "        print(f\"Evaluating model: {model_name} with feature set {i+1}\")\n",
    "        model = train_model(model, X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test set\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Make predictions on the training set\n",
    "        y_train_pred = model.predict(X_train)\n",
    "\n",
    "        # Evaluate the model\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        #print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "        '''  MUST HAVE DELTA_SCORE RANK\n",
    "        # Calculate accuracy of predicting the winner for Delta_ScoreRank > 0.02\n",
    "        subset_idx = X_test['Delta_ScoreRank'].abs() > 0.02\n",
    "        subset_y_test = y_test[subset_idx]\n",
    "        subset_y_pred = y_pred[subset_idx]\n",
    "        y_pred_winner = ['Home' if pred > 0 else 'Away' for pred in subset_y_pred]\n",
    "        y_test_winner = ['Home' if actual > 0 else 'Away' for actual in subset_y_test]\n",
    "        accuracy = accuracy_score(y_test_winner, y_pred_winner)\n",
    "        print(f\"Winner Prediction Accuracy (|Delta_ScoreRank| > 0.02): {accuracy * 100:.2f}%\\n\")\n",
    "        '''\n",
    "\n",
    "        # Calculate accuracy of predicting the winner\n",
    "        y_pred_winner = ['Home' if pred > 0 else 'Away' for pred in y_pred]\n",
    "        y_test_winner = ['Home' if actual > 0 else 'Away' for actual in y_test]\n",
    "        accuracy = accuracy_score(y_test_winner, y_pred_winner)\n",
    "        #print(f\"Winner Prediction Accuracy: {accuracy * 100:.2f}%\\n\")\n",
    "\n",
    "        # Store the results\n",
    "        new_result = pd.DataFrame({\n",
    "            'Model': [model_name],\n",
    "            'Feature_Set': [f'Set {i+1}'],\n",
    "            'MSE': [mse],\n",
    "            'Accuracy': [accuracy * 100]\n",
    "        })\n",
    "        results = pd.concat([results, new_result], ignore_index=True)\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results DataFrame\n",
    "print(results.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the best model and feature set\n",
    "\n",
    "Linear Regression\n",
    "Factors:  ['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank', 'intTerm1', 'intTerm2','intTerm3', 'intTerm4',\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model 11 Summary:\n",
      "\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 Spread   R-squared:                       0.120\n",
      "Model:                            OLS   Adj. R-squared:                  0.110\n",
      "Method:                 Least Squares   F-statistic:                     11.65\n",
      "Date:                Mon, 07 Oct 2024   Prob (F-statistic):           2.85e-17\n",
      "Time:                        11:58:23   Log-Likelihood:                -3153.2\n",
      "No. Observations:                 780   AIC:                             6326.\n",
      "Df Residuals:                     770   BIC:                             6373.\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===================================================================================\n",
      "                      coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------\n",
      "const               2.6380      0.887      2.975      0.003       0.897       4.379\n",
      "Delta_ScoreRank    75.4622     11.557      6.530      0.000      52.776      98.148\n",
      "intTerm1         2170.5022    730.550      2.971      0.003     736.396    3604.608\n",
      "intTerm2        -1363.6251    650.911     -2.095      0.037   -2641.396     -85.854\n",
      "intTerm3         -326.0896    555.904     -0.587      0.558   -1417.356     765.177\n",
      "intTerm4         -292.1061    871.030     -0.335      0.737   -2001.982    1417.769\n",
      "quadTerm1        -248.7945    227.662     -1.093      0.275    -695.706     198.117\n",
      "quadTerm2          16.2206    136.741      0.119      0.906    -252.209     284.650\n",
      "quadTerm3          57.7079    273.470      0.211      0.833    -479.127     594.542\n",
      "quadTerm4        -452.4097    299.005     -1.513      0.131   -1039.372     134.552\n",
      "==============================================================================\n",
      "Omnibus:                        3.045   Durbin-Watson:                   2.026\n",
      "Prob(Omnibus):                  0.218   Jarque-Bera (JB):                3.084\n",
      "Skew:                           0.151   Prob(JB):                        0.214\n",
      "Kurtosis:                       2.942   Cond. No.                     1.84e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.84e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "filtered_played = merged_played[merged_played['Delta_ScoreRank'].abs() > 0.02]\n",
    "X = filtered_played[['Delta_ScoreRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4']]\n",
    "y = filtered_played['Spread']\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "    \n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the linear regression model using statsmodels to see p-values\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "print(f\"\\nModel {i} Summary:\\n\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True  True  True  True False False False  True]\n",
      "[6 3 1 1 1 1 2 4 5 1]\n",
      "[False  True  True  True False False False  True  True False]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "model = LinearRegression()\n",
    "rfe = RFE(model, n_features_to_select=5)\n",
    "rfe = rfe.fit(X, y)\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "selector = SelectKBest(score_func=f_regression, k=5)\n",
    "X_new = selector.fit_transform(X, y)\n",
    "print(selector.get_support())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   VIF Factor         features\n",
      "0    1.145290  Delta_ScoreRank\n",
      "1    4.347253         intTerm1\n",
      "2    3.591348         intTerm2\n",
      "3    3.143727         intTerm3\n",
      "4    4.325440         intTerm4\n",
      "5    2.169210        quadTerm1\n",
      "6    2.287461        quadTerm2\n",
      "7    3.118295        quadTerm3\n",
      "8    2.838891        quadTerm4\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "X = merged_played[['Delta_ScoreRank',\n",
    "                   'intTerm1', 'intTerm2', 'intTerm3', 'intTerm4',\n",
    "                   'quadTerm1', 'quadTerm2', 'quadTerm3', 'quadTerm4']]\n",
    "vif = pd.DataFrame()\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif[\"features\"] = X.columns\n",
    "print(vif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
