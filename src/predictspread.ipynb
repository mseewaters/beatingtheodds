{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive models for NFL games to enable spread betting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages and data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic python packages\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_predict\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score,  r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats.mstats import winsorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression model packages\n",
    "import xgboost as xgb\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.dummy import DummyRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'Week', 'Day', 'Date', 'Time', 'Winner', 'LoserIsHome',\n",
      "       'Loser', 'PtsW', 'PtsL', 'YdsW', 'TOW', 'YdsL', 'TOL', 'season', 'week',\n",
      "       'Winner Abbr', 'Loser Abbr', 'Home Team', 'Away Team', 'Home Score',\n",
      "       'Away Score', 'Winner Yds', 'Loser Yds', 'Margin Yds', 'Winner TO',\n",
      "       'Loser TO', 'Margin TO', 'Margin Pts', 'Total Pts', 'Margin Pct',\n",
      "       'home_team_winner', 'away_win_bonus', 'DateTime',\n",
      "       'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#import data\n",
    "df_results = pd.read_csv('../data/nfl_games_pfr.csv')\n",
    "print(df_results.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create rankings using pagerank from nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "# Graph Functions\n",
    "def create_graph(game_data, week_num):\n",
    "    G = nx.DiGraph()\n",
    "    margin_totals = defaultdict(float)\n",
    "    game_counts = defaultdict(int)\n",
    "    \n",
    "    # Iterate over each game result\n",
    "    for _, row in game_data.iterrows():\n",
    "        winner = row['winner']\n",
    "        loser = row['loser']\n",
    "        week = row['week']\n",
    "        margin = row['margin']\n",
    "\n",
    "        key = (loser, winner)\n",
    "        margin_totals[key] += margin\n",
    "        game_counts[key] += 1\n",
    "\n",
    "    # Add edges with average margin as weight\n",
    "    for (loser, winner), total_margin in margin_totals.items():\n",
    "        avg_margin = total_margin / game_counts[(loser, winner)]\n",
    "        G.add_edge(loser, winner, weight=avg_margin)\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Function to calculate rankings based on the weighted graph\n",
    "def calculate_rankings(graph):\n",
    "    # Calculate PageRank with weights\n",
    "    return pd.DataFrame(nx.pagerank(graph, alpha=0.95, weight='weight').items(), columns=['Team', 'Ranking'])\n",
    "\n",
    "# Function to generate rankings for each season and week\n",
    "def generate_rankings(df_filtered, feature_type):\n",
    "    # Initialize an empty list to store rankings DataFrames\n",
    "    ranking_dfs = []\n",
    "\n",
    "    # Loop over each distinct season in the dataset\n",
    "    for season in df_filtered['season'].unique():\n",
    "        # Filter the game data for the current season\n",
    "        season_data = df_filtered[df_filtered['season'] == season]\n",
    "        \n",
    "        # Loop over the weeks for this season\n",
    "        for week in range(2, season_data['week'].max() + 1):\n",
    "            # Filter the game data up to the current week for the current season\n",
    "            filtered_data = season_data[season_data['week'] <= week]\n",
    "            \n",
    "            # Create the directed graph for the current season and weeks\n",
    "            G = create_graph(filtered_data, week)\n",
    "            \n",
    "            # Calculate the rankings based on the weighted graph\n",
    "            rankings = calculate_rankings(G)\n",
    "\n",
    "            # Round the rankings to 4 decimal places\n",
    "            rankings['Ranking'] = rankings['Ranking'].round(5)\n",
    "            \n",
    "            # Add columns indicating the season and week, with a leading zero for weeks\n",
    "            rankings['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "            rankings['Season'] = season\n",
    "            rankings['Week'] = week\n",
    "            rankings['Type'] = feature_type\n",
    "            \n",
    "            # Append the rankings to the list\n",
    "            ranking_dfs.append(rankings)\n",
    "    \n",
    "    # Concatenate all rankings DataFrames into a single DataFrame\n",
    "    return pd.concat(ranking_dfs)\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Strength of Schedule (SoS)\n",
    "def calculate_strength_of_schedule(graph, pagerank):\n",
    "    sos = defaultdict(float)\n",
    "    for team in graph.nodes:\n",
    "        opponents = list(graph.predecessors(team)) + list(graph.successors(team))\n",
    "        if opponents:\n",
    "            sos[team] = sum(pagerank.get(opponent, 0) for opponent in opponents) / len(opponents)\n",
    "        else:\n",
    "            sos[team] = 0\n",
    "    return sos\n",
    "\n",
    "# Function to generate rankings for each season and week with SoS and iteration\n",
    "def generate_rankings_with_sos(df_filtered, feature_type, iterations=20):\n",
    "    # Initialize an empty list to store rankings DataFrames\n",
    "    ranking_dfs = []\n",
    "\n",
    "    # Loop over each distinct season in the dataset\n",
    "    for season in df_filtered['season'].unique():\n",
    "        # Filter the game data for the current season\n",
    "        season_data = df_filtered[df_filtered['season'] == season]\n",
    "\n",
    "        # Loop over the weeks for this season\n",
    "        for week in range(2, season_data['week'].max() + 1):\n",
    "            # Filter the game data up to the current week for the current season\n",
    "            filtered_data = season_data[season_data['week'] <= week]\n",
    "            \n",
    "            # Create the directed graph for the current season and weeks\n",
    "            G = create_graph(filtered_data, week)\n",
    "            \n",
    "            # Initial PageRank calculation\n",
    "            pagerank = dict(nx.pagerank(G, alpha=0.9, weight='weight'))\n",
    "\n",
    "            # Iteratively refine the rankings with SoS\n",
    "            for _ in range(iterations):\n",
    "                sos = calculate_strength_of_schedule(G, pagerank)\n",
    "                \n",
    "                # Adjust rankings based on strength of schedule\n",
    "                adjusted_pagerank = {}\n",
    "                for team, rank in pagerank.items():\n",
    "                    adjusted_pagerank[team] = rank * (1 + sos[team])  # Adjust by SoS\n",
    "                \n",
    "                # Normalize adjusted PageRank\n",
    "                total_rank = sum(adjusted_pagerank.values())\n",
    "                pagerank = {team: rank / total_rank for team, rank in adjusted_pagerank.items()}\n",
    "\n",
    "            # Convert pagerank dict to DataFrame\n",
    "            rankings = pd.DataFrame(pagerank.items(), columns=['Team', 'Ranking'])\n",
    "\n",
    "            # Round the rankings to 5 decimal places\n",
    "            rankings['Ranking'] = rankings['Ranking'].round(5)\n",
    "            \n",
    "            # Add columns indicating the season and week, with a leading zero for weeks\n",
    "            rankings['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "            rankings['Season'] = season\n",
    "            rankings['Week'] = week\n",
    "            rankings['Type'] = feature_type\n",
    "            \n",
    "            # Append the rankings to the list\n",
    "            ranking_dfs.append(rankings)\n",
    "    \n",
    "    # Concatenate all rankings DataFrames into a single DataFrame\n",
    "    return pd.concat(ranking_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.00811   2024_W02    2024     2  Offense\n",
      "1  BAL  0.01679   2024_W02    2024     2  Offense\n",
      "2  PHI  0.00774   2024_W02    2024     2  Offense\n",
      "3   GB  0.00960   2024_W02    2024     2  Offense\n",
      "4  ATL  0.01486   2024_W02    2024     2  Offense\n",
      "4928\n"
     ]
    }
   ],
   "source": [
    "### OFFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_offense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Yds','Loser Yds','Margin Yds']]\n",
    "df_offense = df_offense.rename(columns={'Winner Yds':'winner', 'Loser Yds':'loser','Margin Yds':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_offense_rankings_df = generate_rankings(df_offense, \"Offense\")\n",
    "final_offense_rankings_df = generate_rankings_with_sos(df_offense, \"Offense\")\n",
    "print(final_offense_rankings_df.head())\n",
    "print(len(final_offense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0  BAL  0.02866   2024_W02    2024     2  Defense\n",
      "1   KC  0.04753   2024_W02    2024     2  Defense\n",
      "2   GB  0.02164   2024_W02    2024     2  Defense\n",
      "3  PHI  0.04544   2024_W02    2024     2  Defense\n",
      "4  PIT  0.01889   2024_W02    2024     2  Defense\n",
      "4928\n"
     ]
    }
   ],
   "source": [
    "### DEFENSE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_defense = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner TO','Loser TO','Margin TO']]\n",
    "df_defense = df_defense.rename(columns={'Winner TO':'winner', 'Loser TO':'loser','Margin TO':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_defense_rankings_df = generate_rankings(df_defense, \"Defense\")\n",
    "final_defense_rankings_df = generate_rankings_with_sos(df_defense, \"Defense\")\n",
    "print(final_defense_rankings_df.head())\n",
    "print(len(final_defense_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week   Type\n",
      "0  BAL  0.01280   2024_W02    2024     2  Score\n",
      "1   KC  0.01972   2024_W02    2024     2  Score\n",
      "2   GB  0.02534   2024_W02    2024     2  Score\n",
      "3  PHI  0.05165   2024_W02    2024     2  Score\n",
      "4  ATL  0.08729   2024_W02    2024     2  Score\n",
      "4928\n"
     ]
    }
   ],
   "source": [
    "### SCORE ###\n",
    "# Filtered data frames for each feature set\n",
    "df_score = df_results[~df_results['Margin Yds'].isna()][['season','week','Winner Abbr','Loser Abbr','Margin Pts']]\n",
    "df_score = df_score.rename(columns={'Winner Abbr':'winner', 'Loser Abbr':'loser', 'Margin Pts':'margin'})\n",
    "\n",
    "# Generate rankings for each feature type\n",
    "#final_score_rankings_df = generate_rankings(df_score, \"Score\")\n",
    "final_score_rankings_df = generate_rankings_with_sos(df_score, \"Score\")\n",
    "print(final_score_rankings_df.head())\n",
    "print(len(final_score_rankings_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Team  Ranking SeasonWeek  Season  Week     Type\n",
      "0   KC  0.00811   2024_W02    2024     2  Offense\n",
      "1  BAL  0.01679   2024_W02    2024     2  Offense\n",
      "2  PHI  0.00774   2024_W02    2024     2  Offense\n",
      "3   GB  0.00960   2024_W02    2024     2  Offense\n",
      "4  ATL  0.01486   2024_W02    2024     2  Offense\n",
      "14784\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all feature rankings into a single DataFrame\n",
    "final_rankings_df = pd.concat([final_offense_rankings_df, final_score_rankings_df, final_defense_rankings_df])\n",
    "print(final_rankings_df.head())\n",
    "print(len(final_rankings_df))\n",
    "final_rankings_df.to_csv('../data/nfl_rankings_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_for_game(game_row, full_data):\n",
    "    current_season = game_row['season']\n",
    "    current_week = game_row['week']\n",
    "    \n",
    "    # Get relevant seasons: current season and previous 3\n",
    "    relevant_seasons = [current_season - i for i in range(4)]\n",
    "    \n",
    "    # Filter data to only include these seasons\n",
    "    filtered_data = full_data[(full_data['season'].isin(relevant_seasons)) & \n",
    "                              ((full_data['season'] < current_season) | \n",
    "                               ((full_data['season'] == current_season) & \n",
    "                                (full_data['week'] < current_week)))]\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Team  Home_Avg_Diff  Away_Avg_Diff  Home_Impact  Away_Impact  \\\n",
      "0     ARI         -6.806          2.417       -9.222        9.222   \n",
      "1     ATL          1.389          6.889       -5.500        5.500   \n",
      "2     BAL         -1.556          1.306       -2.861        2.861   \n",
      "3     BUF         12.333         -9.639       21.972      -21.972   \n",
      "4     CAR          1.222         10.222       -9.000        9.000   \n",
      "...   ...            ...            ...          ...          ...   \n",
      "4346  SEA          6.667         -6.667       13.333      -13.333   \n",
      "4347   SF         -1.000         16.333      -17.333       17.333   \n",
      "4348   TB         -4.333          2.500       -6.833        6.833   \n",
      "4349  TEN         -2.333         10.167      -12.500       12.500   \n",
      "4350  WAS          0.000         -2.667        2.667       -2.667   \n",
      "\n",
      "      Matchup_Count SeasonWeek  \n",
      "0                20   2024_W05  \n",
      "1                20   2024_W05  \n",
      "2                19   2024_W05  \n",
      "3                19   2024_W05  \n",
      "4                19   2024_W05  \n",
      "...             ...        ...  \n",
      "4346             12   2016_W17  \n",
      "4347             12   2016_W17  \n",
      "4348             12   2016_W17  \n",
      "4349             12   2016_W17  \n",
      "4350             12   2016_W17  \n",
      "\n",
      "[4351 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_fieldadv = df_results[~df_results['Margin Yds'].isna()][['season','week','Home Team','Away Team','Home Score', 'Away Score']]\n",
    "df_fieldadv['Margin HomeAway'] = df_fieldadv['Home Score'] - df_fieldadv['Away Score']\n",
    "\n",
    "# List to store the aggregated team-level impacts across all weeks\n",
    "all_team_impacts = []\n",
    "\n",
    "# Dictionary to store performance data for home and away impacts\n",
    "home_away_impacts = []\n",
    "\n",
    "# Iterate over each season and week in the dataset\n",
    "for season in df_fieldadv['season'].unique():\n",
    "    for week in df_fieldadv[df_fieldadv['season'] == season]['week'].unique():\n",
    "        # Filter games up to the current season and week, including the current season and the three prior seasons\n",
    "        relevant_games = df_fieldadv[(df_fieldadv['season'] >= (season - 3)) & ((df_fieldadv['season'] < season) | ((df_fieldadv['season'] == season) & (df_fieldadv['week'] <= week)))]\n",
    "        \n",
    "        # Get a list of unique teams for the relevant period\n",
    "        teams = relevant_games['Home Team'].unique()\n",
    "        \n",
    "        for team in teams:\n",
    "            # Filter games where the team is either home or away\n",
    "            home_games = relevant_games[relevant_games['Home Team'] == team]\n",
    "            away_games = relevant_games[relevant_games['Away Team'] == team]\n",
    "\n",
    "            # Iterate over each opponent the team has faced\n",
    "            for opponent in home_games['Away Team'].unique():\n",
    "                # Check if the team played both a home and away game against this opponent\n",
    "                if opponent in away_games['Home Team'].values:\n",
    "                    # Home game(s) against this opponent\n",
    "                    home_matchups = home_games[home_games['Away Team'] == opponent]\n",
    "                    # Away game(s) against this opponent\n",
    "                    away_matchups = away_games[away_games['Home Team'] == opponent]\n",
    "\n",
    "                    # Ensure there is at least one home and one away game\n",
    "                    if not home_matchups.empty and not away_matchups.empty:\n",
    "                        # Compute the average points differential at home and away\n",
    "                        home_avg_diff = home_matchups['Margin HomeAway'].mean()\n",
    "                        away_avg_diff = away_matchups['Margin HomeAway'].mean()\n",
    "\n",
    "                        # Count the number of matchups used in the calculations\n",
    "                        num_matchups = len(home_matchups) + len(away_matchups)\n",
    "\n",
    "                        # Store the impact data for home and away\n",
    "                        home_away_impacts.append({\n",
    "                            'Team': team,\n",
    "                            'Opponent': opponent,\n",
    "                            'Home_Avg_Diff': home_avg_diff,\n",
    "                            'Away_Avg_Diff': away_avg_diff,\n",
    "                            'Home_Impact': home_avg_diff - away_avg_diff,\n",
    "                            'Away_Impact': away_avg_diff - home_avg_diff,\n",
    "                            'Matchup_Count': num_matchups,\n",
    "                            'SeasonWeek': f\"{season}_W{str(week).zfill(2)}\"\n",
    "                        })\n",
    "\n",
    "        # Convert the results to a DataFrame for the current season and week\n",
    "        home_away_impact_df = pd.DataFrame(home_away_impacts)\n",
    "        \n",
    "        # Filter matchups with more than 3 games for the current season and week\n",
    "        filtered_impact_df = home_away_impact_df[(home_away_impact_df['SeasonWeek'] == f\"{season}_W{str(week).zfill(2)}\") & (home_away_impact_df['Matchup_Count'] > 3)]\n",
    "        \n",
    "        # Group by team and calculate the mean home vs away impact\n",
    "        team_home_away_impact = filtered_impact_df.groupby('Team').agg({\n",
    "            'Home_Avg_Diff': 'mean',\n",
    "            'Away_Avg_Diff': 'mean',\n",
    "            'Home_Impact': 'mean',\n",
    "            'Away_Impact': 'mean',\n",
    "            'Matchup_Count': 'sum'\n",
    "        }).reset_index()\n",
    "        \n",
    "        # Add a column to indicate the current season and week\n",
    "        team_home_away_impact['SeasonWeek'] = f\"{season}_W{str(week).zfill(2)}\"\n",
    "\n",
    "        # Round the aggregated values to 3 decimals\n",
    "        team_home_away_impact = team_home_away_impact.round({'Home_Avg_Diff': 3, 'Away_Avg_Diff': 3, 'Home_Impact': 3, 'Away_Impact': 3})\n",
    "        \n",
    "        # Append the current week's team-level impacts to the overall list\n",
    "        all_team_impacts.append(team_home_away_impact)\n",
    "\n",
    "# Combine all weekly impacts into a single DataFrame\n",
    "final_team_impact_df = pd.concat(all_team_impacts, ignore_index=True)\n",
    "\n",
    "# Print or store the final aggregated team-level impacts\n",
    "print(final_team_impact_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(final_team_impact_df.to_csv(index=False))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create additional features and interaction variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the combined_rankings dataframe to create offensive and defensive rank features\n",
    "rankings = final_rankings_df.pivot(index=['Team', 'SeasonWeek', 'Season', 'Week'], columns='Type', values='Ranking').reset_index()\n",
    "rankings.rename(columns={'Offense': 'OffenseRank', 'Defense': 'DefenseRank', 'Score': 'ScoreRank'}, inplace=True)\n",
    "\n",
    "# Adjust rankings to use the prior week's data\n",
    "rankings['Week'] += 1\n",
    "\n",
    "# Merge the rankings with game results to create the feature set\n",
    "def merge_rankings(df, team_column, prefix):\n",
    "    return df.merge(rankings, left_on=[team_column, 'season', 'week'], right_on=['Team', 'Season', 'Week'], how='left') \\\n",
    "             .rename(columns={'OffenseRank': f'{prefix}_OffenseRank',\n",
    "                              'DefenseRank': f'{prefix}_DefenseRank',\n",
    "                              'ScoreRank': f'{prefix}_ScoreRank'})\n",
    "\n",
    "merged_df = merge_rankings(df_results, 'Home Team', 'Home')\n",
    "merged_df = merge_rankings(merged_df, 'Away Team', 'Away')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "merged_df.drop(columns=['Unnamed: 0', 'Team_x', 'Season_x', 'SeasonWeek_x', 'Week_x',\n",
    "                        'Team_y', 'Season_y', 'SeasonWeek_y', 'Week_y'], inplace=True)\n",
    "\n",
    "# Filter to only games where rankings exist for both teams\n",
    "merged_df.dropna(subset=['Home_OffenseRank', 'Home_DefenseRank', 'Away_OffenseRank', 'Away_DefenseRank'], inplace=True)\n",
    "\n",
    "# Create target variable (spread)\n",
    "merged_df['Spread'] = merged_df.apply(lambda row: row['PtsW'] - row['PtsL']\n",
    "                                      if row['Home Team'] == row['Winner Abbr']\n",
    "                                      else row['PtsL'] - row['PtsW'], axis=1)\n",
    "\n",
    "# Create feature deltas and ratios\n",
    "rank_features = ['OffenseRank', 'DefenseRank', 'ScoreRank']\n",
    "for feature in rank_features:\n",
    "    merged_df[f'Delta_{feature}'] = merged_df[f'Home_{feature}'] - merged_df[f'Away_{feature}']\n",
    "    merged_df[f'Ratio_{feature}'] = merged_df[f'Home_{feature}'] / (merged_df[f'Away_{feature}'] + 1e-5)\n",
    "\n",
    "# Create interaction and quadratic terms\n",
    "interaction_terms = [\n",
    "    ('Home_OffenseRank', 'Away_DefenseRank'),\n",
    "    ('Away_OffenseRank', 'Home_DefenseRank'),\n",
    "    ('Home_OffenseRank', 'Away_OffenseRank'),\n",
    "    ('Away_DefenseRank', 'Home_DefenseRank')\n",
    "]\n",
    "for i, (col1, col2) in enumerate(interaction_terms, 1):\n",
    "    merged_df[f'intTerm{i}'] = merged_df[col1] * merged_df[col2]\n",
    "\n",
    "quadratic_terms = [\n",
    "    'Home_OffenseRank', 'Away_OffenseRank', 'Home_DefenseRank', 'Away_DefenseRank'\n",
    "]\n",
    "for i, col in enumerate(quadratic_terms, 1):\n",
    "    merged_df[f'quadTerm{i}'] = merged_df[col] ** 2\n",
    "\n",
    "# Create strength features\n",
    "merged_df['HomeStrength'] = merged_df['Home_OffenseRank'] + merged_df['Home_DefenseRank'] + merged_df['Home_ScoreRank']\n",
    "merged_df['AwayStrength'] = merged_df['Away_OffenseRank'] + merged_df['Away_DefenseRank'] + merged_df['Away_ScoreRank']\n",
    "\n",
    "# Create variable for historical and future games\n",
    "merged_df['GameType'] = merged_df.apply(lambda row: \"Historical\" \n",
    "                                      if not pd.isna(row['Margin Yds'])\n",
    "                                      else \"Future\", axis=1)\n",
    "\n",
    "print(merged_df.columns)\n",
    "merged_df.to_csv('../data/nfl_games_pfr_features.csv')\n",
    "\n",
    "#Separate played and upcoming games\n",
    "merged_played = merged_df[~merged_df['Margin Yds'].isna()]\n",
    "merged_upcoming = merged_df[merged_df['Margin Yds'].isna()]\n",
    "print(len(merged_played),len(merged_upcoming))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and basic feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model\n",
    "def train_model(model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "filtered_played = merged_played[merged_played['Delta_ScoreRank'].abs() > 0.02]\n",
    "\n",
    "feature_sets = [\n",
    "    filtered_played[['Home_ScoreRank','Away_ScoreRank']], \n",
    "    filtered_played[['Delta_ScoreRank']],\n",
    "    filtered_played[['Ratio_ScoreRank']],\n",
    "    filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank', 'Away_DefenseRank','Away_ScoreRank']],\n",
    "    filtered_played[['Delta_ScoreRank','Delta_OffenseRank','Delta_DefenseRank']],\n",
    "    filtered_played[['Ratio_ScoreRank','Ratio_OffenseRank','Ratio_DefenseRank']],\n",
    "    filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Away_OffenseRank', 'Away_DefenseRank']],\n",
    "    filtered_played[['Delta_OffenseRank','Delta_DefenseRank']],\n",
    "    filtered_played[['Ratio_OffenseRank','Ratio_DefenseRank']],\n",
    "    filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank',\\\n",
    "               'Away_DefenseRank','Away_ScoreRank', 'Delta_ScoreRank','Delta_OffenseRank',\\\n",
    "                'Delta_DefenseRank', 'Ratio_ScoreRank', 'Ratio_OffenseRank', 'Ratio_DefenseRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4', \\\n",
    "                'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', \\\n",
    "                'HomeStrength', 'AwayStrength']],\n",
    "    pd.DataFrame(scaler.fit_transform(filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank',\\\n",
    "               'Away_DefenseRank','Away_ScoreRank', 'Delta_ScoreRank','Delta_OffenseRank',\\\n",
    "                'Delta_DefenseRank', 'Ratio_ScoreRank', 'Ratio_OffenseRank', 'Ratio_DefenseRank',\\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4', \\\n",
    "                'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', \\\n",
    "                'HomeStrength', 'AwayStrength']]))\n",
    "\n",
    "]\n",
    "\n",
    "y = filtered_played['Spread']\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    ('LM', LinearRegression()),\n",
    "    ('LMnoINT', LinearRegression(fit_intercept=False)),\n",
    "    ('Ridge0.05', Ridge(alpha=0.05)),\n",
    "    ('Ridge0.1', Ridge(alpha=0.1)),\n",
    "    ('Ridge0.5', Ridge(alpha=0.5)),  # You can tune the alpha parameter\n",
    "    ('XGBoostBase', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('XGBoost150', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=150, learning_rate=0.1, max_depth=3, random_state=42)),\n",
    "    ('XGBoost5', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.1, max_depth=5, random_state=42)),\n",
    "    ('XGBoost0.5', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=50, learning_rate=0.05, max_depth=3, random_state=42)),\n",
    "    ('RF50', RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)),\n",
    "    ('RF10', RandomForestRegressor(n_estimators=10, max_depth=3, random_state=42)),\n",
    "    ('SVM', SVR(kernel='rbf', C=1.0, epsilon=0.1)),\n",
    "    ('SVMlin', SVR(kernel='linear', C=1.0, epsilon=0.1)),\n",
    "    ('kNN5', KNeighborsRegressor(n_neighbors=5)),\n",
    "    ('kNN17', KNeighborsRegressor(n_neighbors=17)),\n",
    "    ('BaselineAvg', DummyRegressor(strategy='mean'))\n",
    "]\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store results\n",
    "results = pd.DataFrame(columns=['Model', 'Feature_Set', 'Fold', 'MSE', 'Accuracy'])\n",
    "\n",
    "# Define cross-validation strategy (5 folds in this case)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over feature sets and models\n",
    "for i, X in enumerate(feature_sets):\n",
    "    for model_name, model in models:\n",
    "        print(f\"Evaluating model: {model_name} with feature set {i+1}\")\n",
    "        \n",
    "        fold_number = 1\n",
    "        # Cross-validation loop\n",
    "        for train_index, test_index in kf.split(X):\n",
    "            # Use iloc to select rows by integer index\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Train the model\n",
    "            model = train_model(model, X_train, y_train)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Calculate accuracy of predicting the winner\n",
    "            y_pred_winner = ['Home' if pred > 0 else 'Away' for pred in y_pred]\n",
    "            y_test_winner = ['Home' if actual > 0 else 'Away' for actual in y_test]\n",
    "            accuracy = accuracy_score(y_test_winner, y_pred_winner)\n",
    "            \n",
    "            # Store the results for each fold\n",
    "            new_result = pd.DataFrame({\n",
    "                'Model': [model_name],\n",
    "                'Feature_Set': [f'Set {i+1}'],\n",
    "                'Fold': [fold_number],\n",
    "                'MSE': [mse],\n",
    "                'Accuracy': [accuracy * 100]\n",
    "            })\n",
    "            results = pd.concat([results, new_result], ignore_index=True)\n",
    "            \n",
    "            fold_number += 1\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results DataFrame\n",
    "print(results.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize the best model and feature set\n",
    "\n",
    "Models: Random Forest, SVM, XGBoost  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_played = merged_played[merged_played['Delta_ScoreRank'].abs() > 0.02]\n",
    "X = filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank',\\\n",
    "               'Away_DefenseRank','Away_ScoreRank', \\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4', \\\n",
    "                'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', \\\n",
    "                'HomeStrength', 'AwayStrength']]\n",
    "y = filtered_played['Spread']\n",
    "\n",
    "#X = sm.add_constant(X)\n",
    "    \n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=17)\n",
    "\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Random Forest MSE: {mse}\")\n",
    "\n",
    "# Extract feature importance\n",
    "importance = model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to rank the features\n",
    "feature_importance_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display top features\n",
    "print(feature_importance_df)\n",
    "\n",
    "# Initialize RFE with RandomForest as the estimator\n",
    "rfe = RFE(estimator=model, n_features_to_select=10)  # Select top 10 features\n",
    "\n",
    "# Fit RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Get the ranking of features\n",
    "ranking = rfe.ranking_\n",
    "\n",
    "# Identify the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "print(f'Selected features: {selected_features}')\n",
    "\n",
    "# Retrain the model with just the top features\n",
    "X_train_top = X_train[selected_features]\n",
    "X_test_top = X_test[selected_features]\n",
    "\n",
    "rf_model_top = RandomForestRegressor(n_estimators=50, max_depth=3, random_state=42)\n",
    "rf_model_top.fit(X_train_top, y_train)\n",
    "\n",
    "# Evaluate the model with the top features\n",
    "y_pred_top = rf_model_top.predict(X_test_top)\n",
    "mse_top = mean_squared_error(y_test, y_pred_top)\n",
    "print(f'Mean Squared Error with top features: {mse_top}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Define your Random Forest model\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 250],\n",
    "    'max_depth': [2, 3, 5, 7, 9],\n",
    "    'min_samples_split': [2, 5, 10, 25],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2',4]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "rf_random = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, \n",
    "                               n_iter=25, cv=5, random_state=42, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", rf_random.best_params_)\n",
    "best_rf = rf_random.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Support Vector Regressor\n",
    "svr = SVR()\n",
    "\n",
    "# Hyperparameter grid for SVR\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'epsilon': [0.01, 0.1, 1, 10, 50],\n",
    "    'kernel': ['linear', 'poly', 'rbf'],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "# Perform grid search\n",
    "svr_grid = GridSearchCV(estimator=svr, param_grid=param_grid, cv=5, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "svr_grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", svr_grid.best_params_)\n",
    "\n",
    "# Get the best estimator\n",
    "best_svr = svr_grid.best_estimator_\n",
    "\n",
    "y_pred = best_svr.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your XGBoost model\n",
    "xgb_model = xgb.XGBRegressor()\n",
    "\n",
    "# Create the hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Perform randomized search\n",
    "xgb_random = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_grid,\n",
    "                                n_iter=25, cv=5, random_state=42, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best parameters found: \", xgb_random.best_params_)\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "\n",
    "Best model parameters:  \n",
    "RF: {'n_estimators': 50, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 3}\n",
    "SVM: {'C': 100, 'degree': 2, 'epsilon': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
    "XGB: {'subsample': 0.8, 'n_estimators': 200, 'min_child_weight': 1, 'max_depth': 3, 'learning_rate': 0.01, 'gamma': 0.1, 'colsample_bytree': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features and target\n",
    "\n",
    "filtered_played = merged_played[merged_played['Delta_ScoreRank'].abs() > 0.02]\n",
    "\n",
    "X = filtered_played[['Home_OffenseRank', 'Home_DefenseRank','Home_ScoreRank', 'Away_OffenseRank',\\\n",
    "               'Away_DefenseRank','Away_ScoreRank', \\\n",
    "                'intTerm1', 'intTerm2','intTerm3', 'intTerm4', \\\n",
    "                'quadTerm1','quadTerm2', 'quadTerm3', 'quadTerm4', \\\n",
    "                'DaysSinceLastGame_Home', 'DaysSinceLastGame_Away', \\\n",
    "                'HomeStrength', 'AwayStrength']]\n",
    "\n",
    "target_sets = [\n",
    "    filtered_played['Spread'],\n",
    "    filtered_played['Spread'].clip(-15,15),\n",
    "    pd.Series(winsorize(filtered_played['Spread'], limits=[0.05, 0.05])),\n",
    "    pd.Series(winsorize(filtered_played['Spread'], limits=[0.1, 0.1]))\n",
    "]\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    ('LM', LinearRegression()),\n",
    "    ('RF', RandomForestRegressor(n_estimators=50, max_depth=3, min_samples_split=2,min_samples_leaf=1,max_features='sqrt')),\n",
    "    ('SVM', SVR(kernel='linear', C=100, epsilon=10, degree=2)),\n",
    "    ('XGB', xgb.XGBRegressor(n_estimators=200, learning_rate=0.01, max_depth=3, gamma=0.1, subsample=0.8, colsample_bytree=1.0, min_child_weight=1)),\n",
    "    ('BaselineAvg', DummyRegressor(strategy='mean'))\n",
    "]\n",
    "\n",
    "print(\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame to store results\n",
    "results = pd.DataFrame(columns=['Model', 'Feature_Set', 'Fold', 'MSE', 'Accuracy'])\n",
    "\n",
    "# Define cross-validation strategy (5 folds in this case)\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over feature sets and models\n",
    "for i, y in enumerate(target_sets):\n",
    "    for model_name, model in models:\n",
    "        print(f\"Evaluating model: {model_name} with target set {i+1}\")\n",
    "        \n",
    "        fold_number = 1\n",
    "        # Cross-validation loop\n",
    "        for train_index, test_index in kf.split(y):\n",
    "            # Use iloc to select rows by integer index\n",
    "            X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "            y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "            \n",
    "            # Train the model\n",
    "            model = train_model(model, X_train, y_train)\n",
    "\n",
    "            # Make predictions on the test set\n",
    "            y_pred = model.predict(X_test)\n",
    "\n",
    "            # Evaluate the model\n",
    "            mse = mean_squared_error(y_test, y_pred)\n",
    "            \n",
    "            # Calculate accuracy of predicting the winner\n",
    "            y_pred_winner = ['Home' if pred > 0 else 'Away' for pred in y_pred]\n",
    "            y_test_winner = ['Home' if actual > 0 else 'Away' for actual in y_test]\n",
    "            accuracy = accuracy_score(y_test_winner, y_pred_winner)\n",
    "            \n",
    "            # Store the results for each fold\n",
    "            new_result = pd.DataFrame({\n",
    "                'Model': [model_name],\n",
    "                'Feature_Set': [f'Set {i+1}'],\n",
    "                'Fold': [fold_number],\n",
    "                'MSE': [mse],\n",
    "                'Accuracy': [accuracy * 100]\n",
    "            })\n",
    "            results = pd.concat([results, new_result], ignore_index=True)\n",
    "            \n",
    "            fold_number += 1\n",
    "\n",
    "# Print the results DataFrame\n",
    "#print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results DataFrame\n",
    "print(results.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_played = merged_played[merged_played['Delta_ScoreRank'].abs() > 0.02]\n",
    "\n",
    "feature_columns = [\n",
    "    'Home_OffenseRank', 'Home_DefenseRank', 'Home_ScoreRank', 'Away_OffenseRank',\n",
    "    'Away_DefenseRank', 'Away_ScoreRank', 'intTerm1', 'intTerm2', 'intTerm3', 'intTerm4',\n",
    "    'quadTerm1', 'quadTerm2', 'quadTerm3', 'quadTerm4', 'DaysSinceLastGame_Home',\n",
    "    'DaysSinceLastGame_Away', 'HomeStrength', 'AwayStrength'\n",
    "]\n",
    "\n",
    "# Select features and target variable\n",
    "X = filtered_played[feature_columns]\n",
    "y = filtered_played['Spread'].clip(-15, 15)\n",
    "\n",
    "# Define the model\n",
    "model = xgb.XGBRegressor(n_estimators=200, learning_rate=0.01, max_depth=3, gamma=0.1, \n",
    "                            subsample=0.8, colsample_bytree=1.0, min_child_weight=1)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y)\n",
    "\n",
    "# Prepare the data for upcoming games\n",
    "X_new = merged_upcoming[feature_columns]\n",
    "\n",
    "# Predict the spread for upcoming games\n",
    "y_pred_new = model.predict(X_new)\n",
    "\n",
    "# Assign predictions to the merged_upcoming DataFrame (using .loc to avoid SettingWithCopyWarning)\n",
    "merged_upcoming.loc[:, 'Predicted Spread'] = y_pred_new\n",
    "\n",
    "# Print the selected columns\n",
    "print(merged_upcoming[['Home Team', 'Away Team', 'Delta_ScoreRank', 'Predicted Spread']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
